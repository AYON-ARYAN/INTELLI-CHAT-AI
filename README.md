# INTELLI CHAT AI
IntelliChat AI: Your Smart Document & Web Assistant IntelliChat AI is a versatile chatbot powered by LangChain, Streamlit, and Ollama. It offers two powerful modes:  Document Chat: Upload your PDFs and ask questions directly about their content. IntelliChat will intelligently retrieve and synthesize information from your documents. Web & General Chat: Get instant answers to general questions or perform real-time web searches using the Google Custom Search API. Features Document Q&amp;A: Upload multiple PDF files and chat with them. The application chunks documents, creates embeddings using HuggingFaceEmbeddings, and stores them in a Chroma vector database for efficient retrieval. General Conversational AI: Engage in free-form conversations powered by the Mistral model via Ollama. Real-time Web Search: Use the web search: prefix to query the internet and get up-to-date information, powered by the Google Custom Search API. Clean & Intuitive UI: Built with Streamlit, featuring a modern, minimal design for a smooth user experience. Easy Data Management: Clear chat history, and easily clear all uploaded documents and the vector database from the sidebar. How It Works PDF Upload & Processing: Users upload PDF files via the Streamlit interface. These documents are then loaded, split into manageable chunks, and converted into numerical representations (embeddings). Vector Store Creation: The embeddings are stored in a local Chroma vector database, enabling fast and relevant document retrieval. LLM Initialization: The application connects to a local Ollama server running the Mistral large language model for generating responses. Conversational Chain: For document-based queries, LangChain's ConversationalRetrievalChain combines the LLM's intelligence with the document retriever to provide accurate answers from your PDFs, maintaining chat history for context. Web Search Integration: When a "web search" query is detected, the application leverages the Google Custom Search API to fetch real-time results, which are then summarized by the LLM.
